name: Google Maps Scraping

on:
  workflow_dispatch:
    inputs:
      metiers:
        description: 'MÃ©tiers Ã  scraper (JSON array)'
        required: true
        type: string
      departements:
        description: 'DÃ©partements Ã  scraper (JSON array)'
        required: true
        type: string
      max_results:
        description: 'Nombre max de rÃ©sultats par ville'
        required: true
        type: number
        default: 50
      num_threads:
        description: 'Nombre de threads'
        required: true
        type: number
        default: 3
      use_api_communes:
        description: 'Utiliser API data.gouv.fr'
        required: false
        type: boolean
        default: false
      min_pop:
        description: 'Population minimum'
        required: false
        type: number
        default: 0
      max_pop:
        description: 'Population maximum'
        required: false
        type: number
        default: 50000

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 360  # 6 heures max
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y wget gnupg2 unzip curl
          # Install Chrome
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google.list'
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          
          # âœ… Install ChromeDriver (mÃ©thode moderne)
          # RÃ©cupÃ©rer la version de Chrome installÃ©e
          CHROME_VERSION=$(google-chrome --version | grep -oP '\d+\.\d+\.\d+\.\d+' | head -1)
          CHROME_MAJOR_VERSION=$(echo $CHROME_VERSION | cut -d. -f1)
          
          # TÃ©lÃ©charger ChromeDriver correspondant depuis Chrome for Testing
          CHROMEDRIVER_URL="https://storage.googleapis.com/chrome-for-testing-public/${CHROME_VERSION}/linux64/chromedriver-linux64.zip"
          
          # Si l'URL n'existe pas, utiliser la derniÃ¨re version compatible
          if ! curl -f -s -o /dev/null "$CHROMEDRIVER_URL"; then
            # Utiliser la derniÃ¨re version disponible pour cette version majeure
            CHROMEDRIVER_URL="https://storage.googleapis.com/chrome-for-testing-public/LATEST_RELEASE_${CHROME_MAJOR_VERSION}/linux64/chromedriver-linux64.zip"
          fi
          
          wget -O /tmp/chromedriver.zip "$CHROMEDRIVER_URL"
          sudo unzip -o /tmp/chromedriver.zip -d /tmp/
          sudo mv /tmp/chromedriver-linux64/chromedriver /usr/local/bin/chromedriver
          sudo chmod +x /usr/local/bin/chromedriver
          sudo rm -rf /tmp/chromedriver.zip /tmp/chromedriver-linux64
          
          # VÃ©rifier l'installation
          chromedriver --version
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Run scraping
        id: scraping
        env:
          METIERS: ${{ github.event.inputs.metiers }}
          DEPARTEMENTS: ${{ github.event.inputs.departements }}
          MAX_RESULTS: ${{ github.event.inputs.max_results || 50 }}
          NUM_THREADS: ${{ github.event.inputs.num_threads || 3 }}
          USE_API_COMMUNES: ${{ github.event.inputs.use_api_communes || false }}
          MIN_POP: ${{ github.event.inputs.min_pop || 0 }}
          MAX_POP: ${{ github.event.inputs.max_pop || 50000 }}
        run: |
          python scripts/run_scraping_github_actions.py
      
      - name: Upload results as artifact
        uses: actions/upload-artifact@v4
        if: always()  # Upload mÃªme en cas d'Ã©chec
        with:
          name: scraping-results
          path: |
            data/scraping_results_github_actions.json
            data/github_actions_status.json
          retention-days: 7
          if-no-files-found: warn
      
      - name: Summary
        run: |
          echo "## âœ… Scraping terminÃ©" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ“Š RÃ©sultats: $(cat data/scraping_results_github_actions.json | grep -o '"total_results": [0-9]*' | grep -o '[0-9]*') Ã©tablissements scrapÃ©s" >> $GITHUB_STEP_SUMMARY

