# PROMPT TECHNIQUE - CORRECTION CONTAMINATION PANNEAU GOOGLE MAPS

## CONTEXTE

Le scraper extrait correctement les t√©l√©phones et sites web, mais certains √©tablissements **sans site web** se voient attribuer le site web de l'√©tablissement **pr√©c√©dent** (contamination du panneau).

**Exemple observ√© dans les logs :**
- `[7] GT Plomberie77` ‚Üí Site: `https://www.etspicard.fr/...` (mauvais)
- `[11] Julien BREUVART PLOMBERIE` ‚Üí Site: `https://www.etspicard.fr/...` (mauvais)
- `[20] Bati'eau - Plombier Chauffagiste` ‚Üí Site: `https://www.etspicard.fr/...` (mauvais)
- `[21] Brice Gerwig plomberie` ‚Üí Site: `https://www.etspicard.fr/...` (mauvais)

**Pattern observ√© :** Ces √©tablissements utilisent la m√©thode "aria" (backup) et r√©cup√®rent le site du panneau pr√©c√©dent qui n'a pas encore √©t√© rafra√Æchi.

## CODE ACTUEL √Ä CORRIGER

### Fichier : `scraping/google_maps_scraper.py`

### Section 1 : D√©lai apr√®s le clic (ligne ~1880)

```python
# Cliquer pour ouvrir le d√©tail
try:
    self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", element)
    time.sleep(0.3)
    try:
        element.click()
    except:
        self.driver.execute_script("arguments[0].click();", element)
    time.sleep(2.5)  # ‚úÖ FIX CRITIQUE : Augmenter le d√©lai pour √©viter la contamination du panneau
except Exception as e:
    logger.debug(f"  Erreur clic panneau [{index}]: {e}")
```

### Section 2 : Extraction du site web (lignes ~1979-2050)

```python
# ==================== EXTRACTION SITE WEB ====================
try:
    # Attendre que le panneau soit mis √† jour (d√©j√† fait avec le d√©lai de 2.5s apr√®s le clic)
    
    # Priorit√© 1 : a[data-item-id*="authority"] (le plus fiable)
    site_links = search_context.find_elements(By.CSS_SELECTOR, 
        'a[data-item-id*="authority"]'
    )
    
    if site_links:
        for site_link in site_links:
            try:
                href = site_link.get_attribute('href')
                
                if href and ('http://' in href or 'https://' in href):
                    # Filtrer les liens Google Maps
                    if 'google.com' not in href.lower() and \
                       'maps' not in href.lower() and \
                       'goo.gl' not in href.lower() and \
                       'googleapis.com' not in href.lower() and \
                       'aclk' not in href.lower():
                        # Prendre le premier site valide trouv√©
                        info['site_web'] = href
                        logger.info(f"  [{index}] ‚úÖ Site web trouv√©: {href}")
                        break
            except:
                continue
    
    # Priorit√© 2 : aria-label "Visiter le site Web" (backup si m√©thode 1 √©choue)
    if not info.get('site_web'):
        try:
            site_links = search_context.find_elements(By.CSS_SELECTOR, 
                'a[aria-label*="Visiter le site Web"], a[aria-label*="site Web"], a[aria-label*="Website"], a[aria-label*="Site"]'
            )
            for site_link in site_links:
                try:
                    href = site_link.get_attribute('href')
                    if href and ('http://' in href or 'https://' in href):
                        if 'google.com' not in href.lower() and \
                           'maps' not in href.lower() and \
                           'goo.gl' not in href.lower() and \
                           'googleapis.com' not in href.lower() and \
                           'aclk' not in href.lower():
                            info['site_web'] = href
                            logger.info(f"  [{index}] ‚úÖ Site web trouv√© (aria): {href}")
                            break
                except:
                    continue
        except:
            pass
    
    # Si toujours pas trouv√©
    if not info.get('site_web'):
        logger.debug(f"  [{index}] ‚ö†Ô∏è Aucun site web trouv√© pour {info.get('nom', '√©tablissement')}")
except Exception as e:
    logger.debug(f"  Erreur extraction site web (panneau): {e}")
```

## PROBL√àME IDENTIFI√â

1. **Le d√©lai de 2.5 secondes n'est pas suffisant** pour que le panneau se rafra√Æchisse compl√®tement
2. **La m√©thode "aria" (backup) trouve toujours le site du panneau pr√©c√©dent** car elle cherche dans toute la page, pas seulement dans le panneau mis √† jour
3. **Aucune v√©rification que le panneau est bien mis √† jour** avant d'extraire le site web

## SOLUTION √Ä IMPL√âMENTER

### √âtape 1 : V√©rifier que le panneau est mis √† jour AVANT d'extraire le site web

**Ajouter cette v√©rification juste avant l'extraction du site web :**

```python
# ==================== V√âRIFICATION PANNEAU MIS √Ä JOUR ====================
# Attendre que le panneau soit VRAIMENT mis √† jour en v√©rifiant le titre
nom_actuel = info.get('nom', '')
if nom_actuel:
    try:
        # Attendre que le titre du panneau corresponde au nom de l'√©tablissement
        max_attempts = 5
        for attempt in range(max_attempts):
            try:
                titre_panneau = self.driver.find_element(By.CSS_SELECTOR, 'h1[data-attrid="title"]')
                titre_text = titre_panneau.text.strip()
                
                # Nettoyer les deux noms pour comparaison
                nom_clean = nom_actuel.lower().replace('üèÖ', '').replace('üìå', '').strip()[:30]
                titre_clean = titre_text.lower().strip()[:30]
                
                # V√©rifier si le nom correspond au titre (au moins partiellement)
                if nom_clean and titre_clean:
                    # Le nom doit √™tre dans le titre OU le titre doit √™tre dans le nom
                    if nom_clean in titre_clean or titre_clean in nom_clean or \
                       any(word in titre_clean for word in nom_clean.split() if len(word) > 3):
                        logger.debug(f"  [{index}] ‚úÖ Panneau mis √† jour (titre: '{titre_text}')")
                        break
                    else:
                        logger.debug(f"  [{index}] ‚ö†Ô∏è Panneau pas encore √† jour (tentative {attempt+1}/{max_attempts})")
                        logger.debug(f"  [{index}]    Nom: '{nom_actuel}' vs Titre: '{titre_text}'")
                        time.sleep(0.5)  # Attendre 0.5s de plus
            except:
                time.sleep(0.5)
                continue
    except:
        pass
```

### √âtape 2 : Limiter la recherche du site web au panneau de d√©tail uniquement

**Remplacer la section d'extraction du site web par :**

```python
# ==================== EXTRACTION SITE WEB ====================
try:
    # Trouver le panneau de d√©tail ouvert pour limiter la recherche
    panneau_detail = None
    try:
        # Chercher le panneau de d√©tail (le plus √† droite, celui qui vient de s'ouvrir)
        panneaux = self.driver.find_elements(By.CSS_SELECTOR, 
            'div[role="complementary"], div[jsaction*="pane"], div[class*="m6QErb"]'
        )
        
        # Prendre le panneau le plus √† droite (le plus r√©cent)
        if panneaux:
            # Trier par position X (le plus √† droite)
            panneaux_positions = []
            for p in panneaux:
                try:
                    location = p.location
                    panneaux_positions.append((location['x'], p))
                except:
                    continue
            
            if panneaux_positions:
                # Prendre le panneau le plus √† droite
                panneau_detail = max(panneaux_positions, key=lambda x: x[0])[1]
                logger.debug(f"  [{index}] Panneau de d√©tail identifi√© (x={max(panneaux_positions, key=lambda x: x[0])[0]})")
    except:
        pass
    
    # Utiliser le panneau de d√©tail si trouv√©, sinon toute la page
    search_context_site = panneau_detail if panneau_detail else search_context
    
    # Priorit√© 1 : a[data-item-id*="authority"] dans le panneau de d√©tail
    site_links = search_context_site.find_elements(By.CSS_SELECTOR, 
        'a[data-item-id*="authority"]'
    )
    
    if site_links:
        for site_link in site_links:
            try:
                href = site_link.get_attribute('href')
                
                if href and ('http://' in href or 'https://' in href):
                    # Filtrer les liens Google Maps
                    if 'google.com' not in href.lower() and \
                       'maps' not in href.lower() and \
                       'goo.gl' not in href.lower() and \
                       'googleapis.com' not in href.lower() and \
                       'aclk' not in href.lower():
                        info['site_web'] = href
                        logger.info(f"  [{index}] ‚úÖ Site web trouv√©: {href}")
                        break
            except:
                continue
    
    # Priorit√© 2 : aria-label UNIQUEMENT dans le panneau de d√©tail (pas dans toute la page)
    if not info.get('site_web') and panneau_detail:
        try:
            site_links = panneau_detail.find_elements(By.CSS_SELECTOR, 
                'a[aria-label*="Visiter le site Web"], a[aria-label*="site Web"], a[aria-label*="Website"], a[aria-label*="Site"]'
            )
            for site_link in site_links:
                try:
                    href = site_link.get_attribute('href')
                    if href and ('http://' in href or 'https://' in href):
                        if 'google.com' not in href.lower() and \
                           'maps' not in href.lower() and \
                           'goo.gl' not in href.lower() and \
                           'googleapis.com' not in href.lower() and \
                           'aclk' not in href.lower():
                            info['site_web'] = href
                            logger.info(f"  [{index}] ‚úÖ Site web trouv√© (aria dans panneau): {href}")
                            break
                except:
                    continue
        except:
            pass
    
    # Si toujours pas trouv√©
    if not info.get('site_web'):
        logger.debug(f"  [{index}] ‚ö†Ô∏è Aucun site web trouv√© pour {info.get('nom', '√©tablissement')}")
        
except Exception as e:
    logger.debug(f"  Erreur extraction site web (panneau): {e}")
```

## CHANGEMENTS CL√âS

1. **V√©rification du panneau mis √† jour** : Attendre que le titre du panneau corresponde au nom de l'√©tablissement avant d'extraire le site web
2. **Limitation de la recherche au panneau de d√©tail** : Identifier le panneau de d√©tail ouvert et chercher le site web UNIQUEMENT dedans, pas dans toute la page
3. **M√©thode "aria" limit√©e au panneau** : La m√©thode backup (aria-label) ne cherche QUE dans le panneau de d√©tail, pas dans toute la page

## R√âSULTAT ATTENDU

Apr√®s ces modifications :
- Les √©tablissements **sans site web** auront `site_web: None` (pas le site du pr√©c√©dent)
- Les √©tablissements **avec site web** auront leur propre site correct
- Plus de contamination du panneau

## ORDRE D'IMPL√âMENTATION

1. Ajouter la v√©rification du panneau mis √† jour (√âtape 1)
2. Remplacer la section d'extraction du site web (√âtape 2)
3. Tester avec les √©tablissements probl√©matiques (GT Plomberie77, Brice Gerwig, etc.)

