# ğŸš€ Configuration GitHub Actions pour le Scraping

Ce guide explique comment configurer le scraping distant via GitHub Actions.

## ğŸ“‹ PrÃ©requis

1. Un compte GitHub
2. Votre code doit Ãªtre dans un repository GitHub
3. Un Personal Access Token GitHub avec les permissions `repo` et `workflow`

## ğŸ”‘ CrÃ©er un Personal Access Token

1. Allez sur https://github.com/settings/tokens
2. Cliquez sur "Generate new token" â†’ "Generate new token (classic)"
3. Donnez un nom (ex: "Streamlit Scraping")
4. Cochez les permissions :
   - âœ… `repo` (toutes les sous-permissions)
   - âœ… `workflow`
5. Cliquez sur "Generate token"
6. **âš ï¸ IMPORTANT : Copiez le token immÃ©diatement, vous ne pourrez plus le voir aprÃ¨s !**

## âš™ï¸ Configuration dans Streamlit

1. Ouvrez la page **ğŸ” Scraping** dans Streamlit
2. Cochez **"â˜ï¸ Utiliser GitHub Actions (scraping distant, gratuit)"**
3. Entrez votre **Token GitHub** (le Personal Access Token crÃ©Ã© ci-dessus)
4. Entrez votre **Repository GitHub** au format `owner/repo` (ex: `votre-username/scrapping_artisans`)
5. Configurez vos paramÃ¨tres de scraping (mÃ©tiers, dÃ©partements, etc.)
6. Cliquez sur **"â˜ï¸ LANCER SUR GITHUB ACTIONS"**

## ğŸ“Š Suivi du scraping

- Le statut s'affiche en temps rÃ©el dans Streamlit
- Vous pouvez aussi suivre sur GitHub : **Actions** â†’ **Workflows** â†’ **Google Maps Scraping**
- Les rÃ©sultats sont automatiquement tÃ©lÃ©chargÃ©s et sauvegardÃ©s en BDD quand le scraping est terminÃ©

## â±ï¸ Limitations

- **Quota gratuit** : 2000 minutes/mois (suffisant pour ~33h de scraping)
- **Timeout** : 6 heures maximum par run
- **Latence** : ~30-60 secondes pour dÃ©marrer le workflow

## ğŸ”§ DÃ©pannage

### Le workflow ne dÃ©marre pas
- VÃ©rifiez que le token a les bonnes permissions
- VÃ©rifiez que le repository est au bon format (`owner/repo`)
- VÃ©rifiez que le workflow existe dans `.github/workflows/scraping.yml`

### Le scraping Ã©choue
- VÃ©rifiez les logs sur GitHub Actions
- VÃ©rifiez que `requirements.txt` contient toutes les dÃ©pendances
- VÃ©rifiez que le fichier `data/villes_par_departement.json` existe dans le repo

### Les rÃ©sultats ne se tÃ©lÃ©chargent pas
- VÃ©rifiez que le workflow s'est terminÃ© avec succÃ¨s
- VÃ©rifiez que l'artifact "scraping-results" a Ã©tÃ© crÃ©Ã©
- VÃ©rifiez que le token a toujours les permissions `repo`

## ğŸ’¡ Astuces

- Vous pouvez fermer Streamlit pendant le scraping, les rÃ©sultats seront disponibles au retour
- Le scraping continue mÃªme si vous fermez la page
- Vous pouvez lancer plusieurs scrapings en parallÃ¨le (dans la limite du quota)

